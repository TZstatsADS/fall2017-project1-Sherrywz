---
title: "Project 1"
output:
  html_document: default
  html_notebook: default
---

six representative presidents choosed
Wordcloud for three different period
```{r, warning=FALSE, message=FALSE}
#install.packages("tm")  # for text mining
#install.packages("SnowballC") # for text stemming
#install.packages("wordcloud") # word-cloud generator 
#install.packages("RColorBrewer") # color palettes
#install.packages("rvest")
#install.packages("tibble")
#install.packages("qdap")
#install.packages("sentimentr")
#install.packages("gplots")
#install.packages("dplyr")
#install.packages("syuzhet")
#install.packages("beeswarm")
#install.packages("factoextra")
#install.packages("scales")
#install.packages("RANN")
#install.packages("topicmodels")
#install.packages("rJava",type='source')
#install.packages("lda")
#install.packages('servr') 
#install.packages("LDAvis")

# Load
library("tm")
library("SnowballC")
library("wordcloud")
library("RColorBrewer")
library("rvest")
library("tibble")
library("qdap")
library("sentimentr")
library("gplots")
library("dplyr")
library("syuzhet")
library("factoextra")
library("beeswarm")
library("scales")
library("RANN")
library("topicmodels")
library("LDAvis")
library(lda)
#source("/Users/Xiaoyu/Documents/GitHub/adsFall2017/project 1/Fall2017-Project1-RNotebook-master/lib/plotstacked.R")
#source("/Users/Xiaoyu/Documents/GitHub/adsFall2017/project 1/Fall2017-Project1-RNotebook-master/lib/speechFuncs.R")
source("../lib/plotstacked.R")
source("../lib/speechFuncs.R")
print(R.version)
```

```{r}
folder.path="../data/data1"
#folder.path="/Users/Xiaoyu/Documents/GitHub/adsFall2017/project 1/Fall2017-Project1-RNotebook-master/data/data1"
speeches=list.files(path = folder.path, pattern = "*.txt")
prex.out=substr(speeches, 6, nchar(speeches)-4)
ff.doc=Corpus(DirSource(folder.path,encoding="UTF-8"))
#print(prex.out)

ff.doc=tm_map(ff.doc, removeNumbers)  
ff.doc=tm_map(ff.doc, stripWhitespace)
ff.doc=tm_map(ff.doc, content_transformer(tolower))
ff.doc=tm_map(ff.doc, removeWords, stopwords('english'))
ff.doc=tm_map(ff.doc, removeWords, character(0))
ff.doc=tm_map(ff.doc, removePunctuation)
ff.doc=tm_map(ff.doc,removeWords,c("upon","shall","can","many","must","make","much","time","let","among","may","made","will"))
tdm.all=TermDocumentMatrix(ff.doc)

tdm1=as.matrix(tdm.all)
v=sort(rowSums(tdm1),decreasing = TRUE)

wordcloud (ff.doc, scale=c(3,0.5), max.words=100, min.freq=5, random.order=FALSE, rot.per=0.35, use.r.layout=T, random.color=FALSE, colors=brewer.pal(9,"Reds"))
```

```{r}
#folder.path="/Users/Xiaoyu/Documents/GitHub/adsFall2017/project 1/Fall2017-Project1-RNotebook-master/data/data2"
folder.path="../data/data2"

speeches=list.files(path = folder.path, pattern = "*.txt")
prex.out=substr(speeches, 6, nchar(speeches)-4)
ff.doc=Corpus(DirSource(folder.path,encoding="UTF-8"))
#print(prex.out)

ff.doc=tm_map(ff.doc, removeNumbers)  
ff.doc=tm_map(ff.doc, stripWhitespace)
ff.doc=tm_map(ff.doc, content_transformer(tolower))
ff.doc=tm_map(ff.doc, removeWords, stopwords('english'))
ff.doc=tm_map(ff.doc, removeWords, character(0))
ff.doc=tm_map(ff.doc, removePunctuation)
ff.doc=tm_map(ff.doc,removeWords,c("upon","shall","can","many","must","make","much","time","let","among","may","made","will","know","men"))
tdm.all=TermDocumentMatrix(ff.doc)

tdm1=as.matrix(tdm.all)
v=sort(rowSums(tdm1),decreasing = TRUE)

wordcloud (ff.doc, scale=c(3,0.5), max.words=100, min.freq=5, random.order=FALSE, rot.per=0.35, use.r.layout=T, random.color=FALSE, colors=brewer.pal(9,"Blues"))

```


```{r}
#folder.path="/Users/Xiaoyu/Documents/GitHub/adsFall2017/project 1/Fall2017-Project1-RNotebook-master/data/data3"
folder.path="../data/data3"
speeches=list.files(path = folder.path, pattern = "*.txt")
prex.out=substr(speeches, 6, nchar(speeches)-4)
ff.doc=Corpus(DirSource(folder.path,encoding="UTF-8"))
#print(prex.out)

ff.doc=tm_map(ff.doc, removeNumbers)  
ff.doc=tm_map(ff.doc, stripWhitespace)
ff.doc=tm_map(ff.doc, content_transformer(tolower))
ff.doc=tm_map(ff.doc, removeWords, stopwords('english'))
ff.doc=tm_map(ff.doc, removeWords, character(0))
ff.doc=tm_map(ff.doc, removePunctuation)
ff.doc=tm_map(ff.doc,removeWords,c("upon","shall","can","many","must","make","much","time","let","among","may","made","will","know","men","every"))
tdm.all=TermDocumentMatrix(ff.doc)

tdm1=as.matrix(tdm.all)
v=sort(rowSums(tdm1),decreasing = TRUE)

wordcloud (ff.doc, scale=c(3,0.5), max.words=100, min.freq=5, random.order=FALSE, rot.per=0.35, use.r.layout=T, random.color=FALSE, colors=brewer.pal(9,"Greens"))
```

Sentence length
```{r,message=FALSE, warning=FALSE}
#speech.list = read.csv("/Users/Xiaoyu/Documents/GitHub/adsFall2017/project 1/Fall2017-Project1-RNotebook-master/data/speech.list.csv",header = T,as.is = T)
speech.list = read.csv("../data/speech.list.csv",header = T,as.is = T)
sentence.list=NULL
for(i in 1:nrow(speech.list)){
  sentences=sent_detect(speech.list$fulltext[i],
                        endmarks = c("?", ".", "!", "|",";"))
  if(length(sentences)>0){
    emotions=get_nrc_sentiment(sentences)
    word.count=word_count(sentences)
    # colnames(emotions)=paste0("emo.", colnames(emotions))
    # in case the word counts are zeros?
    emotions=diag(1/(word.count+0.01))%*%as.matrix(emotions)
    sentence.list=rbind(sentence.list, 
                        cbind(speech.list[i,-ncol(speech.list)],
                              sentences=as.character(sentences), 
                              word.count,
                              emotions,
                              sent.id=1:length(sentences),row.names = NULL
                              )
    )
  }
}
```

```{r}
sentence.list=
  sentence.list%>%
  filter(!is.na(word.count)) 

sel.comparison=c( "GeorgeWashington","AndrewJackson","FranklinDRoosevelt", "DwightDEisenhower", "GeorgeWBush", "BarackObama")

sentence.list.sel=filter(sentence.list, 
                        type=="inaug",  File%in%sel.comparison)
sentence.list.sel$File=factor(sentence.list.sel$File)
sentence.list.sel$FileOrdered=reorder(sentence.list.sel$File,
                                  sentence.list.sel$word.count,
                                  mean,
                                  order=T)
par(mar=c(4, 11, 2, 2))
beeswarm(word.count~FileOrdered,
         data=sentence.list.sel,
         horizontal = TRUE,
         pch=16, col=alpha(brewer.pal(9, "Set1"), 0.6),
         cex=0.55, cex.axis=0.8, cex.lab=0.8,
         spacing=5/nlevels(sentence.list.sel$FileOrdered),
         las=2, ylab="", xlab="Number of words in a sentence.",
         main="Inaugural Speeches")
```
 
speech length
```{r,warning=FALSE}
library(reshape2)
speech.list2=subset(speech.list,President=="George Washington"|President=="Franklin D. Roosevelt"|President=="Dwight D. Eisenhower"|President=="Andrew Jackson"|President=="Barack Obama"|President=="George W. Bush")
speech.list2=subset(speech.list2,type=="inaug")
speech.list2$Words = as.numeric(speech.list2$Words)
ggplot(data=speech.list2,aes(x=reorder(President,-Words),y=Words,fill=Words))+
   scale_x_discrete(labels = abbreviate)+
   xlab("President")+
   geom_bar(stat="identity",position="dodge",width = 0.8)
```

```{r}
speech.list3=subset(speech.list,type=="inaug")
speech.list3$Words = as.numeric(speech.list3$Words)
speech.list3$President=as.character(speech.list3$President)
speech.list3$President=factor(speech.list3$President,levels=unique(speech.list3$President))
ggplot(data=speech.list3, aes(x=President, y=Words,group=Party, color=Party)) +
    geom_line() +
    geom_point()+
    theme(axis.text.x=element_blank(),
        axis.ticks.x=element_blank())
```

sentiment level
```{r,message=FALSE}
hu.liu.pos = readLines('https://www.dropbox.com/sh/3xctszdxx4n00xq/AAA_Go_Y3kJxQACFaVBem__ea/positive-words.txt?dl=1');
hu.liu.neg = readLines('https://www.dropbox.com/sh/3xctszdxx4n00xq/AABTGWHitlRZcddq1pPXOSqca/negative-words.txt?dl=1');
score.sentiment = function(sentences, pos.words, neg.words, .progress='none')
  {
    require(plyr);
    require(stringr);
    scores = laply(sentences, function(sentence, pos.words, neg.words) {
      sentence = gsub('[^A-z ]','', sentence)
      sentence = tolower(sentence);
      word.list = str_split(sentence, '\\s+');
      words = unlist(word.list);
      pos.matches = match(words, pos.words);
      neg.matches = match(words, neg.words);
      pos.matches = !is.na(pos.matches);
      neg.matches = !is.na(neg.matches);
      score = sum(pos.matches) - sum(neg.matches);
      return(score);
    }, pos.words, neg.words, .progress=.progress );
    scores.df = data.frame(score=scores, text=sentences);
    return(scores.df);
}

par(mfrow=c(2,3))

sample=speech.list2$fulltext[speech.list2$President=="George Washington"]
sample=strsplit(sample,". ",fixed = T)
result1=score.sentiment(sample[[1]],hu.liu.pos,hu.liu.neg)
plot(result1$score,type="o",xlab="index",ylab="sentiment",main="George Washington",pch=19,cex=.5,col="red",panel.first = grid())

sample=speech.list2$fulltext[speech.list2$President=="Andrew Jackson"]
sample=strsplit(sample,". ",fixed = T)
result2=score.sentiment(sample[[1]],hu.liu.pos,hu.liu.neg)
plot(result2$score,type="o",xlab="index",ylab="sentiment",main="Andrew Jackson",pch=19,cex=.5,col="red",panel.first = grid())

sample=speech.list2$fulltext[speech.list2$President=="Franklin D. Roosevelt"]
sample=strsplit(sample,". ",fixed = T)
result3=score.sentiment(sample[[1]],hu.liu.pos,hu.liu.neg)
plot(result3$score,type="o",xlab="index",ylab="sentiment",main="Franklin D. Rooseveltn",pch=19,cex=.5,col="red",panel.first = grid())

sample=speech.list2$fulltext[speech.list2$President=="Dwight D. Eisenhower"]
sample=strsplit(sample,". ",fixed = T)
result4=score.sentiment(sample[[1]],hu.liu.pos,hu.liu.neg)
plot(result4$score,type="o",xlab="index",ylab="sentiment",main="Dwight D. Eisenhower",pch=19,cex=.5,col="red",panel.first = grid())

sample=speech.list2$fulltext[speech.list2$President=="Barack Obama"]
sample=strsplit(sample,". ",fixed = T)
result5=score.sentiment(sample[[1]],hu.liu.pos,hu.liu.neg)
plot(result5$score,type="o",xlab="index",ylab="sentiment",main="Barack Obama",pch=19,cex=.5,col="red",panel.first = grid())

sample=speech.list2$fulltext[speech.list2$President=="George W. Bush"]
sample=strsplit(sample,". ",fixed = T)
result6=score.sentiment(sample[[1]],hu.liu.pos,hu.liu.neg)
plot(result6$score,type="o",xlab="index",ylab="sentiment",main="George W. Bush",pch=19,cex=.5,col="red",panel.first = grid())
```

```{r}
name=c("George Washington 1789","Andrew Jackson 1829","Franklin D. Roosevelt 1933","Dwight D. Eisenhower 1953","Barack Obama 2009","George W. Bush 2001")
num=c(mean(result1$score),mean(result2$score),mean(result3$score),mean(result4$score),mean(result5$score),mean(result6$score))
data=data.frame(name,num)
pre_name=data[[1]]
plot(data$num,ylab="sentiment",main="Average sentiment level for each president",xlab="president",pch=19,cex=1,col="blue",panel.first = grid(),xaxt='n',xlim=c(-1,7))
text(data$num,labels = pre_name,cex= 0.7, pos=2)
```

topic modeling in two parties   LDA method
```{r}
speeches1=speech.list$fulltext[speech.list$type=="inaug"&speech.list$Party=="Republican"]
speeches2=speech.list$fulltext[speech.list$type=="inaug"&speech.list$Party=="Democratic"]
stop_words=stopwords("SMART")

speeches1=gsub("'", "", speeches1)  
speeches1=gsub("[[:punct:]]", " ", speeches1)  
speeches1=gsub("[[:cntrl:]]", " ", speeches1)  
speeches1=gsub("^[[:space:]]+", "", speeches1) 
speeches1=gsub("[[:space:]]+$", "", speeches1) 
speeches1=tolower(speeches1)
speeches2=gsub("'", "", speeches2)  
speeches2=gsub("[[:punct:]]", " ", speeches2)  
speeches2=gsub("[[:cntrl:]]", " ", speeches2)  
speeches2=gsub("^[[:space:]]+", "", speeches2) 
speeches2=gsub("[[:space:]]+$", "", speeches2) 
speeches2=tolower(speeches2)

doc.list1=strsplit(speeches1, "[[:space:]]+")
doc.list2=strsplit(speeches2, "[[:space:]]+")

term.table1=table(unlist(doc.list1))
term.table1=sort(term.table1, decreasing = TRUE)
term.table2=table(unlist(doc.list2))
term.table2=sort(term.table2, decreasing = TRUE)

del1=names(term.table1) %in% stop_words | term.table1 < 2
term.table1 = term.table1[!del1]
vocab1 = names(term.table1)
del2=names(term.table2) %in% stop_words | term.table2 < 2
term.table2 = term.table2[!del2]
vocab2= names(term.table2)

get.terms1=function(x) {
  index=match(x, vocab1)
  index=index[!is.na(index)]
  rbind(as.integer(index - 1), as.integer(rep(1, length(index))))
}
documents1=lapply(doc.list1, get.terms1)
get.terms2=function(x) {
  index=match(x, vocab2)
  index=index[!is.na(index)]
  rbind(as.integer(index - 1), as.integer(rep(1, length(index))))
}
documents2=lapply(doc.list2, get.terms2)

d1=length(documents1) 
w1=length(vocab1) 
doc.length1 =sapply(documents1, function(x) sum(x[2, ]))  
n1=sum(doc.length1) 
term.frequency1 =as.integer(term.table1) 
d2=length(documents2) 
w2=length(vocab2) 
doc.length2 =sapply(documents2, function(x) sum(x[2, ]))  
n2=sum(doc.length2)  
term.frequency2 =as.integer(term.table2)  

k=20
g=5000
alpha=0.02
eta=0.02
set.seed(357)
t11=Sys.time()
fit1=lda.collapsed.gibbs.sampler(documents = documents1, K = k, vocab = vocab1,
                                   num.iterations = g, alpha = alpha,
                                   eta = eta, initial = NULL, burnin = 0,
                                   compute.log.likelihood = TRUE)
t21 =Sys.time()
t21 - t11  
t12=Sys.time()
fit2=lda.collapsed.gibbs.sampler(documents = documents2, K = k, vocab = vocab2,
                                   num.iterations = g, alpha = alpha,
                                   eta = eta, initial = NULL, burnin = 0,
                                   compute.log.likelihood = TRUE)
t22 =Sys.time()
t22 - t12  

theta1 =t(apply(fit1$document_sums + alpha, 2, function(x) x/sum(x)))
phi1=t(apply(t(fit1$topics) + eta, 2, function(x) x/sum(x)))

MovieReviews1=list(phi = phi1,
                     theta = theta1,
                     doc.length = doc.length1,
                     vocab = vocab1,
                     term.frequency = term.frequency1)

theta2 =t(apply(fit2$document_sums + alpha, 2, function(x) x/sum(x)))
phi2=t(apply(t(fit2$topics) + eta, 2, function(x) x/sum(x)))

MovieReviews2=list(phi = phi2,
                     theta = theta2,
                     doc.length = doc.length2,
                     vocab = vocab2,
                     term.frequency = term.frequency2)

json1=createJSON(phi = MovieReviews1$phi,
                  theta = MovieReviews1$theta,
                    doc.length = MovieReviews1$doc.length,
                    vocab = MovieReviews1$vocab,
                    term.frequency = MovieReviews1$term.frequency)
 
 json2=createJSON(phi = MovieReviews2$phi,
                   theta = MovieReviews2$theta,
                    doc.length = MovieReviews2$doc.length,
                    vocab = MovieReviews2$vocab,
                   term.frequency = MovieReviews2$term.frequency)
 
 
 serVis(json1, out.dir = 'vis1', open.browser =F)
 serVis(json2, out.dir = 'vis2', open.browser =F)
 
```
```
















